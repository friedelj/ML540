{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCdLsNvBYGs9ZmTjpiBF7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedelj/ML540/blob/main/jfriedel_USD540_Assignment_5_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# JFriedel Assignment5     USD540                              6/10/25"
      ],
      "metadata": {
        "id": "_9Y100VYf23L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "dltgXMfmf-H_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1REpJENf0A9"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from sagemaker import get_execution_role, image_uris, Session\n",
        "from sagemaker.clarify import (\n",
        "    BiasConfig,\n",
        "    DataConfig,\n",
        "    ModelConfig,\n",
        "    ModelPredictedLabelConfig,\n",
        "    SHAPConfig,\n",
        ")\n",
        "from sagemaker.model import Model\n",
        "from sagemaker.model_monitor import (\n",
        "    BiasAnalysisConfig,\n",
        "    CronExpressionGenerator,\n",
        "    DataCaptureConfig,\n",
        "    EndpointInput,\n",
        "    ExplainabilityAnalysisConfig,\n",
        "    ModelBiasMonitor,\n",
        "    ModelExplainabilityMonitor,\n",
        ")\n",
        "from sagemaker.s3 import S3Downloader, S3Uploader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handful of configuration"
      ],
      "metadata": {
        "id": "J5lgVpz1gJ1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "role = get_execution_role()\n",
        "print(f\"RoleArn: {role}\")\n",
        "\n",
        "sagemaker_session = Session()\n",
        "sagemaker_client = sagemaker_session.sagemaker_client\n",
        "sagemaker_runtime_client = sagemaker_session.sagemaker_runtime_client\n",
        "\n",
        "region = sagemaker_session.boto_region_name\n",
        "print(f\"AWS region: {region}\")\n",
        "\n",
        "# A different bucket can be used, but make sure the role for this notebook has\n",
        "# the s3:PutObject permissions. This is the bucket into which the data is captured\n",
        "bucket = Session().default_bucket()\n",
        "print(f\"Demo Bucket: {bucket}\")\n",
        "prefix = \"sagemaker/DEMO-ClarifyModelMonitor-20200901\"\n",
        "s3_key = f\"s3://{bucket}/{prefix}\"\n",
        "print(f\"S3 key: {s3_key}\")\n",
        "\n",
        "s3_capture_upload_path = f\"{s3_key}/datacapture\"\n",
        "ground_truth_upload_path = f\"{s3_key}/ground_truth_data/{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
        "s3_report_path = f\"{s3_key}/reports\"\n",
        "\n",
        "print(f\"Capture path: {s3_capture_upload_path}\")\n",
        "print(f\"Ground truth path: {ground_truth_upload_path}\")\n",
        "print(f\"Report path: {s3_report_path}\")\n",
        "\n",
        "baseline_results_uri = f\"{s3_key}/baselining\"\n",
        "print(f\"Baseline results uri: {baseline_results_uri}\")\n",
        "\n",
        "endpoint_instance_count = 1\n",
        "endpoint_instance_type = \"ml.m5.large\"\n",
        "schedule_expression = CronExpressionGenerator.hourly()"
      ],
      "metadata": {
        "id": "v32EDX64gNE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model files and data files"
      ],
      "metadata": {
        "id": "F5svQK-Rga7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Print the new working directory to verify\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "6BuH1rB-ghmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move up one directory\n",
        "os.chdir(\"..\")\n",
        "\n",
        "# Print the new working directory to verify\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "92HgZzQPgzIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files and directories in the current working directory\n",
        "contents = os.listdir()\n",
        "print(contents)"
      ],
      "metadata": {
        "id": "JAiT0Mdwg3JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move up one directory\n",
        "os.chdir(\"..\")\n",
        "\n",
        "# Print the new working directory to verify\n",
        "print(\"Current working directory:\", os.getcwd())"
      ],
      "metadata": {
        "id": "3fdwZBJLg7AN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files and directories in the current working directory\n",
        "contents = os.listdir()\n",
        "print(contents)"
      ],
      "metadata": {
        "id": "YAQMwuz4g-N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_file = \"xgb-churn-prediction-model.tar.gz\"\n",
        "test_file = \"upload-test-file.txt\"\n",
        "test_dataset = \"test-dataset-input-cols.csv\"\n",
        "validation_dataset = \"validation-dataset-with-header.csv\"\n",
        "dataset_type = \"text/csv\"\n",
        "\n",
        "with open(validation_dataset) as f:\n",
        "    headers_line = f.readline().rstrip()\n",
        "all_headers = headers_line.split(\",\")\n",
        "label_header = all_headers[0]"
      ],
      "metadata": {
        "id": "a6R9N4G-hBrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deploy the model to Amazon SageMaker"
      ],
      "metadata": {
        "id": "rPl8C8MhhLgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = f\"DEMO-xgb-churn-pred-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
        "print(\"Model name: \", model_name)\n",
        "endpoint_name = f\"DEMO-xgb-churn-model-monitor-{datetime.utcnow():%Y-%m-%d-%H%M}\"\n",
        "print(\"Endpoint name: \", endpoint_name)"
      ],
      "metadata": {
        "id": "nCkABaNLhE6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_uri = image_uris.retrieve(\"xgboost\", region, \"0.90-1\")\n",
        "print(f\"XGBoost image uri: {image_uri}\")\n",
        "model = Model(\n",
        "    role=role,\n",
        "    name=model_name,\n",
        "    image_uri=image_uri,\n",
        "    model_data=model_url,\n",
        "    sagemaker_session=sagemaker_session,\n",
        ")\n",
        "\n",
        "data_capture_config = DataCaptureConfig(\n",
        "    enable_capture=True,\n",
        "    sampling_percentage=100,\n",
        "    destination_s3_uri=s3_capture_upload_path,\n",
        ")\n",
        "print(f\"Deploying model {model_name} to endpoint {endpoint_name}\")\n",
        "model.deploy(\n",
        "    initial_instance_count=endpoint_instance_count,\n",
        "    instance_type=endpoint_instance_type,\n",
        "    endpoint_name=endpoint_name,\n",
        "    data_capture_config=data_capture_config,\n",
        ")"
      ],
      "metadata": {
        "id": "QODkZmBUhTVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "\n",
        "# Create an S3 client\n",
        "s3 = boto3.client('s3')\n",
        "\n",
        "# List all buckets\n",
        "response = s3.list_buckets()\n",
        "\n",
        "# Print bucket names\n",
        "for bucket in response['Buckets']:\n",
        "    print(bucket['Name'])"
      ],
      "metadata": {
        "id": "vtYyO5bWhZvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sagemaker\n",
        "\n",
        "#model_url = \"s3://sagemaker-us-east-1-244989531891/model.tar.gz\"\n",
        "model_url = \"s3://sagemaker-us-east-1-244989531891/xgb-churn-prediction-model.tar.gz\"\n",
        "\n",
        "model = sagemaker.Model(\n",
        "    role=role,\n",
        "    name=model_name,\n",
        "    image_uri=image_uri,\n",
        "    model_data=model_url,  # Now it's defined\n",
        "    sagemaker_session=sagemaker_session,\n",
        ")"
      ],
      "metadata": {
        "id": "qhsX-OGshdhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_uri = image_uris.retrieve(\"xgboost\", region, \"0.90-1\")\n",
        "print(f\"XGBoost image uri: {image_uri}\")\n",
        "model = Model(\n",
        "    role=role,\n",
        "    name=model_name,\n",
        "    image_uri=image_uri,\n",
        "    model_data=model_url,\n",
        "    sagemaker_session=sagemaker_session,\n",
        ")\n",
        "\n",
        "data_capture_config = DataCaptureConfig(\n",
        "    enable_capture=True,\n",
        "    sampling_percentage=100,\n",
        "    destination_s3_uri=s3_capture_upload_path,\n",
        ")\n",
        "print(f\"Deploying model {model_name} to endpoint {endpoint_name}\")\n",
        "model.deploy(\n",
        "    initial_instance_count=endpoint_instance_count,\n",
        "    instance_type=endpoint_instance_type,\n",
        "    endpoint_name=endpoint_name,\n",
        "    data_capture_config=data_capture_config,\n",
        ")"
      ],
      "metadata": {
        "id": "U2s3y2j3hhra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Invoke the deployed modelÔÉÅ"
      ],
      "metadata": {
        "id": "-fGXacgIhnl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait\", end=\"\")\n",
        "test_dataset_size = 0  # record the number of rows in data we're sending for inference\n",
        "with open(test_dataset, \"r\") as f:\n",
        "    for row in f:\n",
        "        if test_dataset_size < 120:\n",
        "            payload = row.rstrip(\"\\n\")\n",
        "            response = sagemaker_runtime_client.invoke_endpoint(\n",
        "                EndpointName=endpoint_name,\n",
        "                Body=payload,\n",
        "                ContentType=dataset_type,\n",
        "            )\n",
        "            prediction = response[\"Body\"].read()\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(0.5)\n",
        "        test_dataset_size += 1\n",
        "\n",
        "print()\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "gazMKzBGhlSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View captured data"
      ],
      "metadata": {
        "id": "w3Ujs0S6h1fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s3://{destination-bucket-prefix}/{endpoint-name}/{variant-name}/yyyy/mm/dd/hh/filename.jsonl"
      ],
      "metadata": {
        "id": "5DaSfFLnh5e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Waiting 30 seconds for captures to show up\", end=\"\")\n",
        "for _ in range(30):\n",
        "    capture_files = sorted(S3Downloader.list(f\"{s3_capture_upload_path}/{endpoint_name}\"))\n",
        "    if capture_files:\n",
        "        break\n",
        "    print(\".\", end=\"\", flush=True)\n",
        "    time.sleep(1)\n",
        "print()\n",
        "print(\"Found Capture Files:\")\n",
        "print(\"\\n \".join(capture_files[-5:]))"
      ],
      "metadata": {
        "id": "n1hsXEiBh-2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "capture_file = S3Downloader.read_file(capture_files[-1]).split(\"\\n\")[-10:-1]\n",
        "print(capture_file[-1])"
      ],
      "metadata": {
        "id": "WRi1B016iC2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start generating some artificial traffic"
      ],
      "metadata": {
        "id": "6H306LGdiF9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "\n",
        "class WorkerThread(threading.Thread):\n",
        "    def __init__(self, do_run, *args, **kwargs):\n",
        "        super(WorkerThread, self).__init__(*args, **kwargs)\n",
        "        self.__do_run = do_run\n",
        "        self.__terminate_event = threading.Event()\n",
        "\n",
        "    def terminate(self):\n",
        "        self.__terminate_event.set()\n",
        "\n",
        "    def run(self):\n",
        "        while not self.__terminate_event.is_set():\n",
        "            self.__do_run(self.__terminate_event)"
      ],
      "metadata": {
        "id": "azycNvNyiJwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invoke_endpoint(terminate_event):\n",
        "    with open(test_dataset, \"r\") as f:\n",
        "        i = 0\n",
        "        for row in f:\n",
        "            payload = row.rstrip(\"\\n\")\n",
        "            response = sagemaker_runtime_client.invoke_endpoint(\n",
        "                EndpointName=endpoint_name,\n",
        "                ContentType=\"text/csv\",\n",
        "                Body=payload,\n",
        "                InferenceId=str(i),  # unique ID per row\n",
        "            )\n",
        "            i += 1\n",
        "            response[\"Body\"].read()\n",
        "            time.sleep(1)\n",
        "            if terminate_event.is_set():\n",
        "                break\n",
        "\n",
        "\n",
        "# Keep invoking the endpoint with test data\n",
        "invoke_endpoint_thread = WorkerThread(do_run=invoke_endpoint)\n",
        "invoke_endpoint_thread.start()"
      ],
      "metadata": {
        "id": "6XK3HBwGiPBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start generating some fake ground truth"
      ],
      "metadata": {
        "id": "IJJB5w1eiTT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "def ground_truth_with_id(inference_id):\n",
        "    random.seed(inference_id)  # to get consistent results\n",
        "    rand = random.random()\n",
        "    # format required by the merge container\n",
        "    return {\n",
        "        \"groundTruthData\": {\n",
        "            \"data\": \"1\" if rand < 0.7 else \"0\",  # randomly generate positive labels 70% of the time\n",
        "            \"encoding\": \"CSV\",\n",
        "        },\n",
        "        \"eventMetadata\": {\n",
        "            \"eventId\": str(inference_id),\n",
        "        },\n",
        "        \"eventVersion\": \"0\",\n",
        "    }\n",
        "\n",
        "\n",
        "def upload_ground_truth(upload_time):\n",
        "    records = [ground_truth_with_id(i) for i in range(test_dataset_size)]\n",
        "    fake_records = [json.dumps(r) for r in records]\n",
        "    data_to_upload = \"\\n\".join(fake_records)\n",
        "    target_s3_uri = f\"{ground_truth_upload_path}/{upload_time:%Y/%m/%d/%H/%M%S}.jsonl\"\n",
        "    print(f\"Uploading {len(fake_records)} records to\", target_s3_uri)\n",
        "    S3Uploader.upload_string_as_file_body(data_to_upload, target_s3_uri)"
      ],
      "metadata": {
        "id": "tnqW7JJuiWKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data for the last hour\n",
        "upload_ground_truth(datetime.utcnow() - timedelta(hours=1))"
      ],
      "metadata": {
        "id": "zMsZYTLFidm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data once a hour\n",
        "def generate_fake_ground_truth(terminate_event):\n",
        "    upload_ground_truth(datetime.utcnow())\n",
        "    for _ in range(0, 60):\n",
        "        time.sleep(60)\n",
        "        if terminate_event.is_set():\n",
        "            break\n",
        "\n",
        "\n",
        "ground_truth_thread = WorkerThread(do_run=generate_fake_ground_truth)\n",
        "ground_truth_thread.start()"
      ],
      "metadata": {
        "id": "F5ukRQJCihht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PART B: Model Bias Monitor"
      ],
      "metadata": {
        "id": "cITiBUomimxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_monitor = ModelBiasMonitor(\n",
        "    role=role,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    max_runtime_in_seconds=1800,\n",
        ")"
      ],
      "metadata": {
        "id": "HLdq72xdiqx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a baselining job"
      ],
      "metadata": {
        "id": "0wQg61UTivJf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configurations"
      ],
      "metadata": {
        "id": "WpFDuHN8ix35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_baselining_job_result_uri = f\"{baseline_results_uri}/model_bias\"\n",
        "model_bias_data_config = DataConfig(\n",
        "    s3_data_input_path=validation_dataset,\n",
        "    s3_output_path=model_bias_baselining_job_result_uri,\n",
        "    label=label_header,\n",
        "    headers=all_headers,\n",
        "    dataset_type=dataset_type,\n",
        ")"
      ],
      "metadata": {
        "id": "WXdbc2mNi12H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_config = BiasConfig(\n",
        "    label_values_or_threshold=[1],\n",
        "    facet_name=\"Account Length\",\n",
        "    facet_values_or_threshold=[100],\n",
        ")"
      ],
      "metadata": {
        "id": "lmR0PM6di4jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_predicted_label_config = ModelPredictedLabelConfig(\n",
        "    probability_threshold=0.8,\n",
        ")"
      ],
      "metadata": {
        "id": "znSzyEZni7gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = ModelConfig(\n",
        "    model_name=model_name,\n",
        "    instance_count=endpoint_instance_count,\n",
        "    instance_type=endpoint_instance_type,\n",
        "    content_type=dataset_type,\n",
        "    accept_type=dataset_type,\n",
        ")"
      ],
      "metadata": {
        "id": "bmrpmRE-i-q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kick off baselining job"
      ],
      "metadata": {
        "id": "N1DreTUijC5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_monitor.suggest_baseline(\n",
        "    model_config=model_config,\n",
        "    data_config=model_bias_data_config,\n",
        "    bias_config=model_bias_config,\n",
        "    model_predicted_label_config=model_predicted_label_config,\n",
        ")\n",
        "print(f\"ModelBiasMonitor baselining job: {model_bias_monitor.latest_baselining_job_name}\")"
      ],
      "metadata": {
        "id": "zgaE6WPpjGXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_monitor.latest_baselining_job.wait(logs=False)\n",
        "model_bias_constraints = model_bias_monitor.suggested_constraints()\n",
        "print()\n",
        "print(f\"ModelBiasMonitor suggested constraints: {model_bias_constraints.file_s3_uri}\")\n",
        "print(S3Downloader.read_file(model_bias_constraints.file_s3_uri))"
      ],
      "metadata": {
        "id": "qnIhmmAfjKK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule model bias monitor"
      ],
      "metadata": {
        "id": "E6SM7ixtjOZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_analysis_config = None\n",
        "if not model_bias_monitor.latest_baselining_job:\n",
        "    model_bias_analysis_config = BiasAnalysisConfig(\n",
        "        model_bias_config,\n",
        "        headers=all_headers,\n",
        "        label=label_header,\n",
        "    )\n",
        "model_bias_monitor.create_monitoring_schedule(\n",
        "    analysis_config=model_bias_analysis_config,\n",
        "    output_s3_uri=s3_report_path,\n",
        "    endpoint_input=EndpointInput(\n",
        "        endpoint_name=endpoint_name,\n",
        "        destination=\"/opt/ml/processing/input/endpoint\",\n",
        "        start_time_offset=\"-PT1H\",\n",
        "        end_time_offset=\"-PT0H\",\n",
        "        probability_threshold_attribute=0.8,\n",
        "    ),\n",
        "    ground_truth_input=ground_truth_upload_path,\n",
        "    schedule_cron_expression=schedule_expression,\n",
        ")\n",
        "print(f\"Model bias monitoring schedule: {model_bias_monitor.monitoring_schedule_name}\")"
      ],
      "metadata": {
        "id": "3LjzTCDOjSJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wait for the first execution"
      ],
      "metadata": {
        "id": "5LXpOwFejXjv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wait_for_execution_to_start(model_monitor):\n",
        "    print(\n",
        "        \"A hourly schedule was created above and it will kick off executions ON the hour (plus 0 - 20 min buffer).\"\n",
        "    )\n",
        "\n",
        "    print(\"Waiting for the first execution to happen\", end=\"\")\n",
        "    schedule_desc = model_monitor.describe_schedule()\n",
        "    while \"LastMonitoringExecutionSummary\" not in schedule_desc:\n",
        "        schedule_desc = model_monitor.describe_schedule()\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(60)\n",
        "    print()\n",
        "    print(\"Done! Execution has been created\")\n",
        "\n",
        "    print(\"Now waiting for execution to start\", end=\"\")\n",
        "    while schedule_desc[\"LastMonitoringExecutionSummary\"][\"MonitoringExecutionStatus\"] in \"Pending\":\n",
        "        schedule_desc = model_monitor.describe_schedule()\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "        time.sleep(10)\n",
        "\n",
        "    print()\n",
        "    print(\"Done! Execution has started\")"
      ],
      "metadata": {
        "id": "tJCM5gKmjbD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wait_for_execution_to_start(model_bias_monitor)"
      ],
      "metadata": {
        "id": "9N_DtnhSjgsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_monitoring_schedule()"
      ],
      "metadata": {
        "id": "mo5lHHefjksB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bias_monitor.stop_monitoring_schedule()"
      ],
      "metadata": {
        "id": "msfeghUZjoL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wait for the execution to finish"
      ],
      "metadata": {
        "id": "K3plO91hjsWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Waits for the schedule to have last execution in a terminal status.\n",
        "def wait_for_execution_to_finish(model_monitor):\n",
        "    schedule_desc = model_monitor.describe_schedule()\n",
        "    execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
        "    if execution_summary is not None:\n",
        "        print(\"Waiting for execution to finish\", end=\"\")\n",
        "        while execution_summary[\"MonitoringExecutionStatus\"] not in [\n",
        "            \"Completed\",\n",
        "            \"CompletedWithViolations\",\n",
        "            \"Failed\",\n",
        "            \"Stopped\",\n",
        "        ]:\n",
        "            print(\".\", end=\"\", flush=True)\n",
        "            time.sleep(60)\n",
        "            schedule_desc = model_monitor.describe_schedule()\n",
        "            execution_summary = schedule_desc[\"LastMonitoringExecutionSummary\"]\n",
        "        print()\n",
        "        print(\"Done! Execution has finished\")\n",
        "    else:\n",
        "        print(\"Last execution not found\")"
      ],
      "metadata": {
        "id": "YGUHC4wNjvqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wait_for_execution_to_finish(model_bias_monitor)"
      ],
      "metadata": {
        "id": "EQFVBEykj0YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect execution results"
      ],
      "metadata": {
        "id": "ZzTt7SsDj6Wn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_desc = model_bias_monitor.describe_schedule()\n",
        "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
        "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
        "    \"Completed\",\n",
        "    \"CompletedWithViolations\",\n",
        "]:\n",
        "    last_model_bias_monitor_execution = model_bias_monitor.list_executions()[-1]\n",
        "    last_model_bias_monitor_execution_report_uri = (\n",
        "        last_model_bias_monitor_execution.output.destination\n",
        "    )\n",
        "    print(f\"Report URI: {last_model_bias_monitor_execution_report_uri}\")\n",
        "    last_model_bias_monitor_execution_report_files = sorted(\n",
        "        S3Downloader.list(last_model_bias_monitor_execution_report_uri)\n",
        "    )\n",
        "    print(\"Found Report Files:\")\n",
        "    print(\"\\n \".join(last_model_bias_monitor_execution_report_files))\n",
        "else:\n",
        "    last_model_bias_monitor_execution = None\n",
        "    print(\n",
        "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "CNSTnfdMj-he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if last_model_bias_monitor_execution:\n",
        "    model_bias_violations = last_model_bias_monitor_execution.constraint_violations()\n",
        "    if model_bias_violations:\n",
        "        print(model_bias_violations.body_dict)"
      ],
      "metadata": {
        "id": "vO2nmgKxkHpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PART C: Model Explainability Monitor"
      ],
      "metadata": {
        "id": "100cLXwykLIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_monitor = ModelExplainabilityMonitor(\n",
        "    role=role,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    max_runtime_in_seconds=1800,\n",
        ")"
      ],
      "metadata": {
        "id": "epJhICehkKom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a baselining job"
      ],
      "metadata": {
        "id": "8YvSzydakRaw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "H97jpJ5ykU8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_baselining_job_result_uri = f\"{baseline_results_uri}/model_explainability\"\n",
        "model_explainability_data_config = DataConfig(\n",
        "    s3_data_input_path=validation_dataset,\n",
        "    s3_output_path=model_explainability_baselining_job_result_uri,\n",
        "    label=label_header,\n",
        "    headers=all_headers,\n",
        "    dataset_type=dataset_type,\n",
        ")"
      ],
      "metadata": {
        "id": "ZKqCdPuikZdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here use the mean value of test dataset as SHAP baseline\n",
        "test_dataframe = pd.read_csv(test_dataset, header=None)\n",
        "shap_baseline = [list(test_dataframe.mean())]\n",
        "\n",
        "shap_config = SHAPConfig(\n",
        "    baseline=shap_baseline,\n",
        "    num_samples=100,\n",
        "    agg_method=\"mean_abs\",\n",
        "    save_local_shap_values=False,\n",
        ")"
      ],
      "metadata": {
        "id": "igQxhDMGkeCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kick off baselining job"
      ],
      "metadata": {
        "id": "wl85pzHhkh02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_monitor.suggest_baseline(\n",
        "    data_config=model_explainability_data_config,\n",
        "    model_config=model_config,\n",
        "    explainability_config=shap_config,\n",
        ")\n",
        "print(\n",
        "    f\"ModelExplainabilityMonitor baselining job: {model_explainability_monitor.latest_baselining_job_name}\"\n",
        ")"
      ],
      "metadata": {
        "id": "Vixomyzqkliv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_monitor.latest_baselining_job.wait(logs=False)\n",
        "model_explainability_constraints = model_explainability_monitor.suggested_constraints()\n",
        "print()\n",
        "print(\n",
        "    f\"ModelExplainabilityMonitor suggested constraints: {model_explainability_constraints.file_s3_uri}\"\n",
        ")\n",
        "print(S3Downloader.read_file(model_explainability_constraints.file_s3_uri))"
      ],
      "metadata": {
        "id": "lzCVb1Xwkrxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Schedule model explainability monitor"
      ],
      "metadata": {
        "id": "kEuXLXkUkwPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_analysis_config = None\n",
        "if not model_explainability_monitor.latest_baselining_job:\n",
        "    # Remove label because only features are required for the analysis\n",
        "    headers_without_label_header = copy.deepcopy(all_headers)\n",
        "    headers_without_label_header.remove(label_header)\n",
        "    model_explainability_analysis_config = ExplainabilityAnalysisConfig(\n",
        "        explainability_config=shap_config,\n",
        "        model_config=model_config,\n",
        "        headers=headers_without_label_header,\n",
        "    )\n",
        "model_explainability_monitor.create_monitoring_schedule(\n",
        "    output_s3_uri=s3_report_path,\n",
        "    endpoint_input=endpoint_name,\n",
        "    schedule_cron_expression=schedule_expression,\n",
        ")"
      ],
      "metadata": {
        "id": "sAbXdv_Ckzo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wait for execution and inspect analysis results"
      ],
      "metadata": {
        "id": "B37DnxA7k7Dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_explainability_monitor.stop_monitoring_schedule()"
      ],
      "metadata": {
        "id": "3DXo3SDqk-1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wait further for the execution to finish, then inspect its analysis results,"
      ],
      "metadata": {
        "id": "v2yPo2N0lQ41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedule_desc = model_explainability_monitor.describe_schedule()\n",
        "execution_summary = schedule_desc.get(\"LastMonitoringExecutionSummary\")\n",
        "if execution_summary and execution_summary[\"MonitoringExecutionStatus\"] in [\n",
        "    \"Completed\",\n",
        "    \"CompletedWithViolations\",\n",
        "]:\n",
        "    last_model_explainability_monitor_execution = model_explainability_monitor.list_executions()[-1]\n",
        "    last_model_explainability_monitor_execution_report_uri = (\n",
        "        last_model_explainability_monitor_execution.output.destination\n",
        "    )\n",
        "    print(f\"Report URI: {last_model_explainability_monitor_execution_report_uri}\")\n",
        "    last_model_explainability_monitor_execution_report_files = sorted(\n",
        "        S3Downloader.list(last_model_explainability_monitor_execution_report_uri)\n",
        "    )\n",
        "    print(\"Found Report Files:\")\n",
        "    print(\"\\n \".join(last_model_explainability_monitor_execution_report_files))\n",
        "else:\n",
        "    last_model_explainability_monitor_execution = None\n",
        "    print(\n",
        "        \"====STOP==== \\n No completed executions to inspect further. Please wait till an execution completes or investigate previously reported failures.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "mq-n_97flVnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if last_model_explainability_monitor_execution:\n",
        "    model_explainability_violations = (\n",
        "        last_model_explainability_monitor_execution.constraint_violations()\n",
        "    )\n",
        "    if model_explainability_violations:\n",
        "        print(model_explainability_violations.body_dict)"
      ],
      "metadata": {
        "id": "xie54iRMlhsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PART D: Cleanup"
      ],
      "metadata": {
        "id": "Y6dFPgJglkFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First stop the worker threads,"
      ],
      "metadata": {
        "id": "xx889P0Alm6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "invoke_endpoint_thread.terminate()\n",
        "ground_truth_thread.terminate()"
      ],
      "metadata": {
        "id": "x4SJWXbQlqam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Then stop all monitors scheduled for the endpoint"
      ],
      "metadata": {
        "id": "UuF9sjxhluye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sagemaker.predictor import Predictor\n",
        "\n",
        "predictor = Predictor(endpoint_name, sagemaker_session=sagemaker_session)\n",
        "model_monitors = predictor.list_monitors()\n",
        "for model_monitor in model_monitors:\n",
        "    model_monitor.stop_monitoring_schedule()\n",
        "    wait_for_execution_to_finish(model_monitor)\n",
        "    model_monitor.delete_monitoring_schedule()"
      ],
      "metadata": {
        "id": "5oV-kEpJlxv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally delete the endpoint"
      ],
      "metadata": {
        "id": "E8Tspf-Yl89W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictor.delete_endpoint()\n",
        "predictor.delete_model()"
      ],
      "metadata": {
        "id": "gH0vC96HmCsk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}