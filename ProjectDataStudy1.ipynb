{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNljuA4oJKIlZkoa9Fkkaom",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/friedelj/ML540/blob/main/ProjectDataStudy1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code attempts to study the Kaggle Autism data, out of SAGEMAKER"
      ],
      "metadata": {
        "id": "wmgHk9W1kBAN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9rzAfRLibJ8"
      },
      "outputs": [],
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn tensorflow shap plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import shap\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve,\n",
        "    classification_report\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "wiL9S4SdkFJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and clean data\n",
        "df = pd.read_csv(\"Autistic Spectrum Disorder Screening for Children.csv\")\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "gb_rcrfikFjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace '?' with NaN and drop missing\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "4jURBWbekVrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode target variable (binary)\n",
        "df['Class/ASD'] = df['Class/ASD'].apply(lambda x: 1 if x == 'YES' else 0)"
      ],
      "metadata": {
        "id": "StXF06-xkVoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode binary categorical fields\n",
        "binary_columns = ['jundice', 'austim', 'used_app_before', 'gender']\n",
        "for col in binary_columns:\n",
        "    df[col] = df[col].apply(lambda x: 1 if str(x).lower() in ['yes', 'm', 'male', 'true', '1'] else 0)"
      ],
      "metadata": {
        "id": "FcrV3AtIkVk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode all other categorical features using Label Encoding\n",
        "categorical_cols = ['ethnicity', 'contry_of_res', 'age_desc', 'relation']\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "vACiLD5WkVhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any remaining non-numeric or unneeded columns\n",
        "if 'result' in df.columns:\n",
        "    df = df.drop(columns=['result'])  # 'result' might be redundant with features"
      ],
      "metadata": {
        "id": "_ZaGBNNokVeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop(columns=['Class/ASD'])\n",
        "y = df['Class/ASD']"
      ],
      "metadata": {
        "id": "baOU2wbjkVbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "90VdwOdlkVXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering - correlation\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(df.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qhNvtPtJkVTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/test/val split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
      ],
      "metadata": {
        "id": "Ec_11YR4kVK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize numerical values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val   = scaler.transform(X_val)\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "77rispQkkFXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "model = models.Sequential([\n",
        "    layers.Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "oH7ZUguqkign"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "832QEehVkidS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "start_time = time.time()\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=30, batch_size=16, verbose=1\n",
        ")\n",
        "inference_time = time.time() - start_time"
      ],
      "metadata": {
        "id": "cfrVCSaRkiaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train label distribution:\", np.bincount(y_train))\n",
        "print(\"Validation label distribution:\", np.bincount(y_val))\n",
        "print(\"Test label distribution:\", np.bincount(y_test))"
      ],
      "metadata": {
        "id": "b7bPam54kiW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "y_pred_prob = model.predict(X_test).ravel()\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "icWIZSmNlDJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "07F6SlgUlDF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Test label distribution:\", np.bincount(y_test))\n",
        "\n",
        "if len(np.unique(y_test)) < 2:\n",
        "    print(\"ROC AUC cannot be computed because only one class is present in y_test.\")\n",
        "else:\n",
        "    print(f\"AUC: {roc_auc_score(y_test, y_pred_prob):.2f}\")"
      ],
      "metadata": {
        "id": "Mx2jSgeXlDCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r9q6o9PalC_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "I0hheZjIlC7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance using SHAP\n",
        "explainer = shap.DeepExplainer(model, X_train[:100])\n",
        "shap_values = explainer.shap_values(X_test[:100])"
      ],
      "metadata": {
        "id": "J0hnkJbRlC4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHAP Summary Plot\n",
        "import shap\n",
        "\n",
        "# Use a small background dataset for SHAP\n",
        "background = X_train[:100]\n",
        "\n",
        "# SHAP expects a model that outputs probability\n",
        "explainer = shap.DeepExplainer(model, background)\n",
        "\n",
        "# Compute SHAP values for test samples\n",
        "shap_values = explainer.shap_values(X_test[:100])\n",
        "\n",
        "# Check if model output is binary classification (1 output neuron)\n",
        "# shap_values will be a list of arrays\n",
        "if isinstance(shap_values, list) and len(shap_values) == 1:\n",
        "    shap.summary_plot(shap_values[0], X_test[:100], feature_names=X.columns)\n",
        "else:\n",
        "    # For multiclass or other cases\n",
        "    shap.summary_plot(shap_values, X_test[:100], feature_names=X.columns)"
      ],
      "metadata": {
        "id": "7bkkSZcflCzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jKofDHY6lCry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRfL84jwkiTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJgLnDzukiPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4rHZxg8kiGr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}